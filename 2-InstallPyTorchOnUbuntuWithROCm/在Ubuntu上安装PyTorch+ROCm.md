

# åœ¨ Ubuntu 24.04.2 + ROCm ç¯å¢ƒä¸‹å®‰è£… PyTorch

---

## âœ… å¿…è¦æ¡ä»¶ç¡®è®¤

åœ¨å¼€å§‹å‰ï¼Œè¯·ç¡®ä¿ç³»ç»Ÿæ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š

* [x] æ“ä½œç³»ç»Ÿï¼šUbuntu 24.04.2 LTS
* [x] å†…æ ¸ç‰ˆæœ¬ï¼š**6.11**ï¼ˆä¸å¯ä¸º 6.14 åŠä»¥ä¸Šï¼‰
* [x] ROCm å·²æ­£ç¡®å®‰è£…ï¼Œ`rocm-smi` å’Œ `rocminfo` å¯æ­£å¸¸è¾“å‡º
* [x] å·²è¿æ¥ç½‘ç»œï¼Œå¯è®¿é—® PyTorch å’Œ ROCm çš„å®˜æ–¹é•œåƒæº

---

## ğŸ¯ æœ¬èŠ‚ç›®æ ‡

* å®‰è£… Anaconda æˆ– Mambaï¼ˆUVï¼‰ä½œä¸º Python åŒ…ç®¡ç†å™¨
* åˆ›å»ºç‹¬ç«‹ç¯å¢ƒå¹¶å®‰è£… PyTorchï¼ˆå¸¦ ROCm æ”¯æŒï¼‰
* è¿è¡Œç¤ºä¾‹ç¨‹åºæµ‹è¯• PyTorch æ˜¯å¦èƒ½è¯†åˆ« AMD GPU
* ï¼ˆå¯é€‰ï¼‰æ‰©å±•ï¼šå®‰è£… Transformersã€Dataloader æµ‹è¯•ç­‰

---

## ğŸ“¦ æ­¥éª¤ 1ï¼šå®‰è£… Anaconda / Mambaï¼ˆUVï¼‰

æ¨èä½¿ç”¨è½»é‡çº§çš„ Conda æ›¿ä»£å“ **Mambaï¼ˆuvï¼‰**ï¼Œå®‰è£…æ›´å¿«ã€‚ä½ ä¹Ÿå¯ä»¥é€‰æ‹©å®˜æ–¹ Anacondaã€‚

### æ–¹å¼ä¸€ï¼šå®‰è£… Anaconda

```bash
wget https://repo.anaconda.com/archive/Anaconda3-2024.02-1-Linux-x86_64.sh
bash Anaconda3-2024.02-1-Linux-x86_64.sh
```

å®‰è£…å®Œæˆåè¿è¡Œï¼š

```bash
source ~/.bashrc
conda --version
```

---

### æ–¹å¼äºŒï¼ˆæ¨èï¼‰ï¼šå®‰è£… Mamba (conda + UV)

```bash
curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba
mkdir -p ~/mambaforge
./bin/micromamba shell init -s bash -p ~/mambaforge
source ~/.bashrc
micromamba create -n torch-rocm python=3.10 -y
micromamba activate torch-rocm
```

---

## ğŸ”§ æ­¥éª¤ 2ï¼šå®‰è£… PyTorchï¼ˆROCm ç‰ˆï¼‰

å‚è€ƒ AMD å®˜æ–¹æä¾›çš„ PyTorch ROCm wheelï¼š

### å®‰è£…å‘½ä»¤ï¼ˆé€‚ç”¨äº ROCm 6.4.x + Python 3.1*ï¼‰ï¼š

```bash
pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.4
```




### å®‰è£…å‘½ä»¤ï¼ˆé€‚ç”¨äº ROCm 6.3.x + Python 3.1*ï¼‰ï¼š

```bash
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3
```

> è‹¥æç¤ºæ‰¾ä¸åˆ° wheelï¼Œè¯·ç¡®ä¿ä½ çš„ Python æ˜¯ 3.10+ ä¸”å¹³å°ä¸º x86\_64ã€‚


---

## âœ… æ­¥éª¤ 3ï¼šéªŒè¯ GPU æ˜¯å¦å¯ç”¨

è¿è¡Œä»¥ä¸‹ Python è„šæœ¬ï¼š

```python
import torch

print("PyTorch version:", torch.__version__)
print("ROCm available:", torch.version.hip)
print("Is ROCm GPU available:", torch.cuda.is_available())
print("Device count:", torch.cuda.device_count())
print("Current device:", torch.cuda.current_device())
print("Device name:", torch.cuda.get_device_name(0))
```

### é¢„æœŸè¾“å‡ºç¤ºä¾‹ï¼ˆAI MAX 395ï¼‰ï¼š

```
PyTorch version: 2.3.0+rocm6.4
ROCm available: True
Is ROCm GPU available: True
Device count: 1
Current device: 0
Device name: AMD Radeon Graphics (gfx1100)
```

è‹¥èƒ½æ­£ç¡®è¯†åˆ«å‡º gfx1100 ç­‰è®¾å¤‡ï¼Œå³è¡¨ç¤ºå®‰è£…æˆåŠŸã€‚

---

## ğŸ“š æ‰©å±•å†…å®¹ï¼ˆå¯é€‰ï¼‰

### 1. å®‰è£… Transformers ç­‰æ·±åº¦å­¦ä¹ åº“

```bash
pip install transformers accelerate tqdm
```

### 2. è¿è¡Œæ¨ç†æµ‹è¯•

```python
from transformers import pipeline

pipe = pipeline("text-generation", model="EleutherAI/gpt-neo-125M", device=0)
print(pipe("Hello, I'm using ROCm", max_length=30))
```

ï¼ˆè‹¥æ¨¡å‹ä¸æ”¯æŒ ROCmï¼Œä¼š fallback åˆ° CPUï¼‰

---

## ğŸ“Œ å°ç»“

ä½ ç°åœ¨å·²ç»æˆåŠŸï¼š

* å®‰è£… Python åŒ…ç®¡ç†å™¨ï¼ˆConda / Mambaï¼‰
* å®‰è£…å¹¶éªŒè¯ ROCm ç‰ˆæœ¬çš„ PyTorch
* æˆåŠŸè¿è¡ŒåŸºç¡€æ¨ç†ç¨‹åº

å¦‚éœ€åœ¨ JupyterLabã€Docker æˆ–å¤š GPU ç³»ç»Ÿä¸­ä½¿ç”¨ PyTorch + ROCmï¼Œæˆ‘å¯ä»¥ç»§ç»­ä¸ºä½ æä¾›è¯¦ç»†é…ç½®æ•™ç¨‹ã€‚æ˜¯å¦ç»§ç»­ï¼Ÿ
